{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972e3140-e984-453a-83bf-e79f2a7257ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 1: Wu-Palmer Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "868f4bcb-7995-4ef2-9fdd-4368a9bdea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.11/site-packages (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.11/site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.11/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Collecting en-core-web-md==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /opt/conda/lib/python3.11/site-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n",
      "Requirement already satisfied: enchant in /opt/conda/lib/python3.11/site-packages (0.0.1)\n",
      "Requirement already satisfied: textblob in /opt/conda/lib/python3.11/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.11/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk>=3.1->textblob) (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "!pip install -U spacy\n",
    "import spacy\n",
    "!python -m spacy download en_core_web_md \n",
    "sp = spacy.load('en_core_web_md')\n",
    "\n",
    "!pip install -U enchant\n",
    "import enchant\n",
    "from enchant.utils import levenshtein\n",
    "\n",
    "!pip install -U textblob\n",
    "import textblob\n",
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b6a56cff-877d-4dec-8644-4e129553877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dict = {}\n",
    "with open(\"embeddings_final/word_embeddings_25.txt\") as embeddings:\n",
    "    emb_dict = json.load(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "f1876aa1-7be8-4431-88e9-658f73249053",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_fem = {}\n",
    "white_mal = {}\n",
    "black_fem = {}\n",
    "black_mal = {}\n",
    "mixed_fem = {}\n",
    "mixed_mal = {}\n",
    "asian_fem = {}\n",
    "asian_mal = {}\n",
    "for key in emb_dict.keys():\n",
    "    word_info = key.split(\"_\")\n",
    "    word = word_info[0]\n",
    "    ethnic = word_info[1]\n",
    "    gender = word_info[2]\n",
    "    if ethnic == \"white\":\n",
    "        if gender == \"female\":\n",
    "            white_fem[word] = emb_dict[key]\n",
    "        else:\n",
    "            white_mal[word] = emb_dict[key]\n",
    "    elif ethnic == \"black\":\n",
    "        if gender == \"female\":\n",
    "            black_fem[word] = emb_dict[key]\n",
    "        else:\n",
    "            black_mal[word] = emb_dict[key]\n",
    "    elif ethnic == \"mixed\":\n",
    "        if gender == \"female\":\n",
    "            mixed_fem[word] = emb_dict[key]\n",
    "        else:\n",
    "            mixed_mal[word] = emb_dict[key]\n",
    "    elif ethnic == \"asian\":\n",
    "        if gender == \"female\":\n",
    "            asian_fem[word] = emb_dict[key]\n",
    "        else:\n",
    "            asian_mal[word] = emb_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "d006813a-bb15-4fa1-bdd1-71b2a3dc3dbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def wu_palmer_calcs(dict1, dict2, sim_dict, dict_name, file_name):\n",
    "    avg_file = open(f\"embedding_similarities/skip_gram_wup/{file_name}.txt\", \"a\")\n",
    "    for word in dict1.keys():\n",
    "        counter = 0\n",
    "        if len(dict1[word]) > 0:\n",
    "            sim_dict[word] = 0\n",
    "            if len(dict1[word]) > 0 and len(dict2[word]) > 0:\n",
    "                for embed1 in dict1[word]:\n",
    "                    for embed2 in dict2[word]:\n",
    "                        text = f\"{embed1} {embed2}\"\n",
    "                        tokens = sp(text)\n",
    "                        sim_score = tokens[0].similarity(tokens[1])\n",
    "                        syn1 = wn.synsets(embed1)\n",
    "                        syn2 = wn.synsets(embed2)\n",
    "                        if len(syn1) > 0 and len(syn2) > 0:\n",
    "                            synonyms = []\n",
    "                            c1 = 0\n",
    "                            for s1 in syn1:\n",
    "                                if s1.name().split(\".\")[0] == embed1:\n",
    "                                    synonyms.append(s1)\n",
    "                                    break\n",
    "                            for s2 in syn2:\n",
    "                                if s2.name().split(\".\")[0] == embed2:\n",
    "                                    synonyms.append(s2)\n",
    "                                    break\n",
    "                            if len(synonyms) > 1:\n",
    "                                synon1 = synonyms[0].name().split(\".\")[0]\n",
    "                                synon2 = synonyms[1].name().split(\".\")[0]\n",
    "                                wup = synonyms[0].wup_similarity(synonyms[1])\n",
    "                                m = max(sim_score, wup)\n",
    "                                sim_dict[word] += m\n",
    "                            else:\n",
    "                                sim_dict[word] += sim_score\n",
    "                full_length = len(dict1[word]) * len(dict2[word])\n",
    "                sim_dict[word] /= full_length\n",
    "    sorted_avgs = dict(sorted(sim_dict.items(), key=lambda item: item[1]))\n",
    "    for word in sorted_avgs.keys():\n",
    "        avg_file.write(f\"{dict_name}[{word}] = {sorted_avgs[word]}\\n\")\n",
    "    avg_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "d6eed8ac-fdee-4ccf-ab66-3419c514ca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/2262384559.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "white_black_fem_avg_sims = {}\n",
    "wu_palmer_calcs(white_fem, black_fem, white_black_fem_avg_sims, \"white_black_fem_avg_sims\", \"white_black_f_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "c34dd401-1b2c-4985-a13f-cf1d51c0ab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/2262384559.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "white_black_mal_avg_sims = {}\n",
    "wu_palmer_calcs(white_mal, black_mal, white_black_mal_avg_sims, \"white_black_mal_avg_sims\", \"white_black_m_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "55cb9a50-8b7d-4f78-8c63-0eb51fff1536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/2262384559.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "white_asian_fem_avg_sims = {}\n",
    "wu_palmer_calcs(white_fem, asian_fem, white_asian_fem_avg_sims, \"white_asian_fem_avg_sims\", \"white_asian_f_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "b016dad6-c666-46e7-9043-b49026c792a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/2262384559.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "white_asian_mal_avg_sims = {}\n",
    "wu_palmer_calcs(white_mal, asian_mal, white_asian_mal_avg_sims, \"white_asian_mal_avg_sims\", \"white_asian_m_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "c4b7d57a-3429-4846-86da-e3ab5f8e174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/2262384559.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "white_mixed_fem_avg_sims = {}\n",
    "wu_palmer_calcs(white_fem, mixed_fem, white_mixed_fem_avg_sims, \"white_mixed_fem_avg_sims\", \"white_mixed_f_avg_sim_skipgram\")\n",
    "\n",
    "white_mixed_mal_avg_sims = {}\n",
    "wu_palmer_calcs(white_mal, mixed_mal, white_mixed_mal_avg_sims, \"white_mixed_mal_avg_sims\", \"white_mixed_m_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "575451be-01b8-4093-99fa-76e724b7004a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/2262384559.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "mixed_black_fem_avg_sims = {}\n",
    "wu_palmer_calcs(mixed_fem, black_fem, mixed_black_fem_avg_sims, \"mixed_black_fem_avg_sims\", \"mixed_black_f_avg_sim_skipgram\")\n",
    "\n",
    "mixed_black_mal_avg_sims = {}\n",
    "wu_palmer_calcs(mixed_mal, black_mal, mixed_black_mal_avg_sims, \"mixed_black_mal_avg_sims\", \"mixed_black_m_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "13a5dca0-e59f-4906-9403-cd8ac7be74b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/2262384559.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "asian_black_fem_avg_sims = {}\n",
    "wu_palmer_calcs(asian_fem, black_fem, asian_black_fem_avg_sims, \"asian_black_fem_avg_sims\", \"asian_black_f_avg_sim_skipgram\")\n",
    "\n",
    "asian_black_mal_avg_sims = {}\n",
    "wu_palmer_calcs(asian_mal, black_mal, asian_black_mal_avg_sims, \"asian_black_mal_avg_sims\", \"asian_black_m_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "d3962408-2239-40f4-96b8-0efe0b33e80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/2262384559.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "asian_mixed_fem_avg_sims = {}\n",
    "wu_palmer_calcs(asian_fem, mixed_fem, asian_mixed_fem_avg_sims, \"asian_mixed_fem_avg_sims\", \"asian_mixed_f_avg_sim_skipgram\")\n",
    "\n",
    "asian_mixed_mal_avg_sims = {}\n",
    "wu_palmer_calcs(asian_mal, mixed_mal, asian_mixed_mal_avg_sims, \"asian_mixed_mal_avg_sims\", \"asian_mixed_m_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "e23d3e01-7bab-4f48-be25-a46431b8bff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/2262384559.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "black_genders_avg_sims = {}\n",
    "wu_palmer_calcs(black_fem, black_mal, black_genders_avg_sims, \"black_genders_avg_sims\", \"black_genders_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "25a66d2b-d149-43a0-ad58-0ad6f404c811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/2262384559.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "white_genders_avg_sims = {}\n",
    "wu_palmer_calcs(white_fem, white_mal, white_genders_avg_sims, \"white_genders_avg_sims\", \"white_genders_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "04fbcb61-a06b-49af-8e82-492830617825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/2262384559.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "mixed_genders_avg_sims = {}\n",
    "wu_palmer_calcs(mixed_fem, mixed_mal, mixed_genders_avg_sims, \"mixed_genders_avg_sims\", \"mixed_genders_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "3e3a71bc-d7cf-405b-8b54-85a020d2b652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/2262384559.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "asian_genders_avg_sims = {}\n",
    "wu_palmer_calcs(asian_fem, asian_mal, asian_genders_avg_sims, \"asian_genders_avg_sims\", \"asian_genders_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "c8fe0170-09a4-4b0d-9c0c-556a0bfcc941",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar czf wu_palmer_comparisons.tar.gz embedding_similarities/skip_gram_wup/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a81fb-25b3-400e-8b6f-c82d9e883af8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 2: Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "c12fabae-6795-4e61-8dbd-d34889b1fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "ba566615-e018-4d90-b2d8-c13a37f1b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vocab(model, top_n = None):\n",
    "    count = 0\n",
    "    if top_n is not None:\n",
    "        for index, word in enumerate(model.wv.index_to_key):\n",
    "            count+= 1\n",
    "            if count < top_n:\n",
    "                print(f\"WORD #{index}/{len(model.wv.index_to_key)} IS: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "983bb050-ac2a-43df-afa6-d8b80ec98163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_align_gensim(m1, m2, words=None):\n",
    "    vocab_m1 = set(m1.wv.index_to_key)\n",
    "    vocab_m2 = set(m2.wv.index_to_key)\n",
    "    common_vocab = vocab_m1 & vocab_m2\n",
    "    if words: common_vocab &= set(words)\n",
    "    if not vocab_m1 - common_vocab and not vocab_m2 - common_vocab:\n",
    "        return (m1,m2)\n",
    "\n",
    "    common_vocab = list(common_vocab)\n",
    "    common_vocab.sort(key=lambda w: m1.wv.get_vecattr(w, \"count\") + m2.wv.get_vecattr(w, \"count\"), reverse=True)\n",
    "    for m in [m1, m2]:\n",
    "        indices = [m.wv.key_to_index[w] for w in common_vocab]\n",
    "        old_arr = m.wv.vectors\n",
    "        new_arr = np.array([old_arr[index] for index in indices])\n",
    "        m.wv.vectors = new_arr\n",
    "\n",
    "        new_key_to_index = {}\n",
    "        new_index_to_key = []\n",
    "        for new_index, key in enumerate(common_vocab):\n",
    "            new_key_to_index[key] = new_index\n",
    "            new_index_to_key.append(key)\n",
    "        m.wv.key_to_index = new_key_to_index\n",
    "        m.wv.index_to_key = new_index_to_key\n",
    "        \n",
    "        print(len(m.wv.key_to_index), len(m.wv.vectors))\n",
    "        \n",
    "    return (m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "21aa4b4f-90d4-493f-86f3-b07d104af490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_procrustes_align_gensim(base_embed, other_embed, words=None):\n",
    "    in_base_embed, in_other_embed = intersection_align_gensim(base_embed, other_embed, words=words)\n",
    "\n",
    "    base_vecs = in_base_embed.wv.get_normed_vectors()\n",
    "    other_vecs = in_other_embed.wv.get_normed_vectors()\n",
    "\n",
    "    m = other_vecs.T.dot(base_vecs) \n",
    "    u, _, v = np.linalg.svd(m)\n",
    "    ortho = u.dot(v) \n",
    "    other_embed.wv.vectors = (other_embed.wv.vectors).dot(ortho)    \n",
    "    \n",
    "    return other_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "46c71ff9-c9a8-4fdd-95a6-6f33060677d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_fem_mod = Word2Vec.load(\"white_models/cbow_w10_f1_1000_ns_half_neg2\")\n",
    "white_mal_mod = Word2Vec.load(\"white_models/cbow_w3_f1_1000\")\n",
    "\n",
    "black_fem_mod = Word2Vec.load(\"black_models/cbow_w10_f1_1000_ns_half_neg3\")\n",
    "black_mal_mod = Word2Vec.load(\"black_models/cbow_w10_f1_1000_mc2\")\n",
    "\n",
    "mixed_fem_mod = Word2Vec.load(\"mixed_models/cbow_w10_f1_1000_mc2\")\n",
    "mixed_mal_mod = Word2Vec.load(\"mixed_models/cbow_w10_f1_1000_mc2\")\n",
    "\n",
    "asian_fem_mod = Word2Vec.load(\"asian_models/cbow_w10_f1_1000\")\n",
    "asian_mal_mod = Word2Vec.load(\"asian_models/cbow_w10_f1_1000_mc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "56dcbc88-f197-4f1b-90c2-f1bcedb271e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(model1, model2, word):\n",
    "  sc = 1 - spatial.distance.cosine(model1.wv[word], model2.wv[word])\n",
    "  return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "2303bcae-80fd-46aa-bb53-62cb1c87790c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5207 5207\n",
      "5207 5207\n",
      "Created dataframe for white-black female comparison\n",
      "1843 1843\n",
      "1843 1843\n",
      "Created dataframe for white-black male comparison\n",
      "2910 2910\n",
      "2910 2910\n",
      "Created dataframe for white-asian female comparison\n",
      "1074 1074\n",
      "1074 1074\n",
      "Created dataframe for white-asian male comparison\n",
      "1001 1001\n",
      "1001 1001\n",
      "Created dataframe for white-mixed female comparison\n",
      "933 933\n",
      "933 933\n",
      "Created dataframe for white-mixed male comparison\n",
      "2742 2742\n",
      "2742 2742\n",
      "Created dataframe for black-asian female comparison\n",
      "864 864\n",
      "864 864\n",
      "Created dataframe for black-asian male comparison\n",
      "988 988\n",
      "988 988\n",
      "Created dataframe for black-mixed female comparison\n",
      "738 738\n",
      "738 738\n",
      "Created dataframe for black-asian male comparison\n",
      "888 888\n",
      "888 888\n",
      "Created dataframe for asian-mixed female comparison\n",
      "585 585\n",
      "585 585\n",
      "Created dataframe for asian-mixed male comparison\n",
      "4855 4855\n",
      "4855 4855\n",
      "Created dataframe for white male & female comparison\n",
      "1865 1865\n",
      "1865 1865\n",
      "Created dataframe for black male & female comparison\n",
      "Created dataframe for mixed male & female comparison\n",
      "1004 1004\n",
      "1004 1004\n",
      "Created dataframe for asian male & female comparison\n"
     ]
    }
   ],
   "source": [
    "# black and white fem\n",
    "smart_procrustes_align_gensim(white_fem_mod, black_fem_mod, words=None)\n",
    "cosine_sim_wbf = pd.DataFrame(([w, cosine_similarity(white_fem_mod, black_fem_mod, w), white_fem_mod.wv.get_vecattr(w, \"count\") , black_fem_mod.wv.get_vecattr(w, \"count\") ] for w in white_fem_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for white-black female comparison\")\n",
    "# black and white male\n",
    "smart_procrustes_align_gensim(white_mal_mod, black_mal_mod, words=None)\n",
    "cosine_sim_wbm = pd.DataFrame(([w, cosine_similarity(white_mal_mod, black_mal_mod, w), white_mal_mod.wv.get_vecattr(w, \"count\") , black_mal_mod.wv.get_vecattr(w, \"count\") ] for w in white_mal_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for white-black male comparison\")\n",
    "\n",
    "# reset wf, bf, wm, bm\n",
    "white_fem_mod = Word2Vec.load(\"white_models/cbow_w10_f1_1000_ns_half_neg2\")\n",
    "black_fem_mod = Word2Vec.load(\"black_models/cbow_w10_f1_1000_ns_half_neg3\")\n",
    "white_mal_mod = Word2Vec.load(\"white_models/cbow_w3_f1_1000\")\n",
    "black_mal_mod = Word2Vec.load(\"black_models/cbow_w10_f1_1000_mc2\")\n",
    "\n",
    "# white and asian fem\n",
    "smart_procrustes_align_gensim(white_fem_mod, asian_fem_mod, words=None)\n",
    "cosine_sim_waf = pd.DataFrame(([w, cosine_similarity(white_fem_mod, asian_fem_mod, w), white_fem_mod.wv.get_vecattr(w, \"count\") , asian_fem_mod.wv.get_vecattr(w, \"count\") ] for w in white_fem_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for white-asian female comparison\")\n",
    "# white and asian male\n",
    "smart_procrustes_align_gensim(white_mal_mod, asian_mal_mod, words=None)\n",
    "cosine_sim_wam = pd.DataFrame(([w, cosine_similarity(white_mal_mod, asian_mal_mod, w), white_mal_mod.wv.get_vecattr(w, \"count\") , asian_mal_mod.wv.get_vecattr(w, \"count\") ] for w in white_mal_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for white-asian male comparison\")\n",
    "\n",
    "# reset wf, af, wm, am\n",
    "white_fem_mod = Word2Vec.load(\"white_models/cbow_w10_f1_1000_ns_half_neg2\")\n",
    "asian_fem_mod = Word2Vec.load(\"asian_models/cbow_w10_f1_1000\")\n",
    "white_mal_mod = Word2Vec.load(\"white_models/cbow_w3_f1_1000\")\n",
    "asian_mal_mod = Word2Vec.load(\"asian_models/cbow_w10_f1_1000_mc2\")\n",
    "\n",
    "# white and mixed fem\n",
    "smart_procrustes_align_gensim(white_fem_mod, mixed_fem_mod, words=None)\n",
    "cosine_sim_wmf = pd.DataFrame(([w, cosine_similarity(white_fem_mod, mixed_fem_mod, w), white_fem_mod.wv.get_vecattr(w, \"count\") , mixed_fem_mod.wv.get_vecattr(w, \"count\") ] for w in white_fem_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for white-mixed female comparison\")\n",
    "# white and asian male\n",
    "smart_procrustes_align_gensim(white_mal_mod, mixed_mal_mod, words=None)\n",
    "cosine_sim_wmm = pd.DataFrame(([w, cosine_similarity(white_mal_mod, mixed_mal_mod, w), white_mal_mod.wv.get_vecattr(w, \"count\") , mixed_mal_mod.wv.get_vecattr(w, \"count\") ] for w in white_mal_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for white-mixed male comparison\")\n",
    "\n",
    "# reset wf, mf, wm, mm\n",
    "white_fem_mod = Word2Vec.load(\"white_models/cbow_w10_f1_1000_ns_half_neg2\")\n",
    "mixed_fem_mod = Word2Vec.load(\"mixed_models/cbow_w10_f1_1000_mc2\")\n",
    "white_mal_mod = Word2Vec.load(\"white_models/cbow_w3_f1_1000\")\n",
    "mixed_mal_mod = Word2Vec.load(\"mixed_models/cbow_w10_f1_1000_mc2\")\n",
    "\n",
    "# black and asian fem\n",
    "smart_procrustes_align_gensim(black_fem_mod, asian_fem_mod, words=None)\n",
    "cosine_sim_baf = pd.DataFrame(([w, cosine_similarity(black_fem_mod, asian_fem_mod, w), black_fem_mod.wv.get_vecattr(w, \"count\") , asian_fem_mod.wv.get_vecattr(w, \"count\") ] for w in black_fem_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for black-asian female comparison\")\n",
    "# black and asian male\n",
    "smart_procrustes_align_gensim(black_mal_mod, asian_mal_mod, words=None)\n",
    "cosine_sim_bam = pd.DataFrame(([w, cosine_similarity(black_mal_mod, asian_mal_mod, w), black_mal_mod.wv.get_vecattr(w, \"count\") , asian_mal_mod.wv.get_vecattr(w, \"count\") ] for w in black_mal_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for black-asian male comparison\")\n",
    "\n",
    "# reset af, bf, am, bm\n",
    "asian_fem_mod = Word2Vec.load(\"asian_models/cbow_w10_f1_1000\")\n",
    "black_fem_mod = Word2Vec.load(\"black_models/cbow_w10_f1_1000_ns_half_neg3\")\n",
    "asian_mal_mod = Word2Vec.load(\"asian_models/cbow_w10_f1_1000_mc2\")\n",
    "black_mal_mod = Word2Vec.load(\"black_models/cbow_w10_f1_1000_mc2\")\n",
    "\n",
    "# black and mixed fem\n",
    "smart_procrustes_align_gensim(black_fem_mod, mixed_fem_mod, words=None)\n",
    "cosine_sim_bmf = pd.DataFrame(([w, cosine_similarity(black_fem_mod, mixed_fem_mod, w), black_fem_mod.wv.get_vecattr(w, \"count\") , mixed_fem_mod.wv.get_vecattr(w, \"count\") ] for w in black_fem_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for black-mixed female comparison\")\n",
    "# black and mixed male\n",
    "smart_procrustes_align_gensim(black_mal_mod, mixed_mal_mod, words=None)\n",
    "cosine_sim_bmm = pd.DataFrame(([w, cosine_similarity(black_mal_mod, mixed_mal_mod, w), black_mal_mod.wv.get_vecattr(w, \"count\") , mixed_mal_mod.wv.get_vecattr(w, \"count\") ] for w in black_mal_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for black-asian male comparison\")\n",
    "\n",
    "# reset mf, bf, mm, bm\n",
    "mixed_fem_mod = Word2Vec.load(\"mixed_models/cbow_w10_f1_1000_mc2\")\n",
    "black_fem_mod = Word2Vec.load(\"black_models/cbow_w10_f1_1000_ns_half_neg3\")\n",
    "mixed_mal_mod = Word2Vec.load(\"mixed_models/cbow_w10_f1_1000_mc2\")\n",
    "black_mal_mod = Word2Vec.load(\"black_models/cbow_w10_f1_1000_mc2\")\n",
    "\n",
    "# asian and mixed fem\n",
    "smart_procrustes_align_gensim(asian_fem_mod, mixed_fem_mod, words=None)\n",
    "cosine_sim_amf = pd.DataFrame(([w, cosine_similarity(asian_fem_mod, mixed_fem_mod, w), asian_fem_mod.wv.get_vecattr(w, \"count\") , mixed_fem_mod.wv.get_vecattr(w, \"count\") ] for w in asian_fem_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for asian-mixed female comparison\")\n",
    "# asian and mixed male\n",
    "smart_procrustes_align_gensim(asian_mal_mod, mixed_mal_mod, words=None)\n",
    "cosine_sim_amm = pd.DataFrame(([w, cosine_similarity(asian_mal_mod, mixed_mal_mod, w), asian_mal_mod.wv.get_vecattr(w, \"count\") , mixed_mal_mod.wv.get_vecattr(w, \"count\") ] for w in asian_mal_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for asian-mixed male comparison\")\n",
    "\n",
    "# reset mf, af, mm, am\n",
    "mixed_fem_mod = Word2Vec.load(\"mixed_models/cbow_w10_f1_1000_mc2\")\n",
    "asian_fem_mod = Word2Vec.load(\"asian_models/cbow_w10_f1_1000\")\n",
    "mixed_mal_mod = Word2Vec.load(\"mixed_models/cbow_w10_f1_1000_mc2\")\n",
    "asian_mal_mod = Word2Vec.load(\"asian_models/cbow_w10_f1_1000_mc2\")\n",
    "\n",
    "# white fem and male\n",
    "smart_procrustes_align_gensim(white_fem_mod, white_mal_mod, words=None)\n",
    "cosine_sim_w_gend = pd.DataFrame(([w, cosine_similarity(white_fem_mod, white_mal_mod, w), white_fem_mod.wv.get_vecattr(w, \"count\") , white_mal_mod.wv.get_vecattr(w, \"count\") ] for w in white_fem_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for white male & female comparison\")\n",
    "\n",
    "# black fem and male\n",
    "smart_procrustes_align_gensim(black_fem_mod, black_mal_mod, words=None)\n",
    "cosine_sim_b_gend = pd.DataFrame(([w, cosine_similarity(black_fem_mod, black_mal_mod, w), black_fem_mod.wv.get_vecattr(w, \"count\") , black_mal_mod.wv.get_vecattr(w, \"count\") ] for w in black_fem_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for black male & female comparison\")\n",
    "\n",
    "# mixed fem and male\n",
    "smart_procrustes_align_gensim(mixed_fem_mod, mixed_mal_mod, words=None)\n",
    "cosine_sim_m_gend = pd.DataFrame(([w, cosine_similarity(mixed_fem_mod, mixed_mal_mod, w), mixed_fem_mod.wv.get_vecattr(w, \"count\") , mixed_mal_mod.wv.get_vecattr(w, \"count\") ] for w in mixed_fem_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for mixed male & female comparison\")\n",
    "\n",
    "# asian fem and male\n",
    "smart_procrustes_align_gensim(asian_fem_mod, asian_mal_mod, words=None)\n",
    "cosine_sim_a_gend = pd.DataFrame(([w, cosine_similarity(asian_fem_mod, asian_mal_mod, w), asian_fem_mod.wv.get_vecattr(w, \"count\") , asian_mal_mod.wv.get_vecattr(w, \"count\") ] for w in asian_fem_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for asian male & female comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "98096431-76ca-458e-8e04-44742182ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cos_sim(eth_gen_dict, word_list, file_name, cos_sim_dict):        \n",
    "    comparisons = cos_sim_dict[cos_sim_dict['word'].isin(word_list)]\n",
    "    comparisons.sort_values(by=['similarity'], inplace=True)\n",
    "    for index in range(comparisons.shape[0]):\n",
    "        eth_gen_dict[comparisons['word'].iloc[index]] = comparisons['similarity'].iloc[index]\n",
    "    with open(f'embedding_similarities/cosine_sim/{file_name}.txt', 'w') as curr_file:\n",
    "        json.dump(eth_gen_dict, curr_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d0727888-e886-4850-abbd-8b25ca2aae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_black_fem_cosine = {}\n",
    "calc_cos_sim(white_black_fem_cosine,  white_black_fem_avg_sims.keys(), \"white_black_fem_cos_sim\", cosine_sim_wbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d2a5609a-6b2b-4a63-9a66-1cc64b21acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_black_mal_cosine = {}\n",
    "calc_cos_sim(white_black_mal_cosine,  white_black_mal_avg_sims.keys(), \"white_black_mal_cos_sim\", cosine_sim_wbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "5fa4fda3-5efc-49bd-95e8-e01ff4163979",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_asian_fem_cosine = {}\n",
    "calc_cos_sim(white_asian_fem_cosine,  white_asian_fem_avg_sims.keys(), \"white_asian_fem_cos_sim\", cosine_sim_waf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "eaa8edb3-1b39-40f5-ba1d-5e0a8c6c42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_asian_mal_cosine = {}\n",
    "calc_cos_sim(white_asian_mal_cosine,  white_asian_mal_avg_sims.keys(), \"white_asian_mal_cos_sim\", cosine_sim_wam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "40b816bb-441b-403d-b584-01e67f7c7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_mixed_fem_cosine = {}\n",
    "calc_cos_sim(white_mixed_fem_cosine,  white_mixed_fem_avg_sims.keys(), \"white_mixed_fem_cos_sim\", cosine_sim_wmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "eae36ed5-19a5-4f5a-b3f3-5d3c23bca9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_mixed_mal_cosine = {}\n",
    "calc_cos_sim(white_mixed_mal_cosine,  white_mixed_mal_avg_sims.keys(), \"white_mixed_mal_cos_sim\", cosine_sim_wmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "9f2d035e-7666-4fc0-aeac-f7e9ed67a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_asian_fem_cosine = {}\n",
    "calc_cos_sim(black_asian_fem_cosine,  asian_black_fem_avg_sims.keys(), \"black_asian_fem_cos_sim\", cosine_sim_baf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "db2e96ed-8f4f-4c8f-8410-4a3c8cbb0bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_asian_mal_cosine = {}\n",
    "calc_cos_sim(black_asian_mal_cosine,  asian_black_mal_avg_sims.keys(), \"black_asian_mal_cos_sim\", cosine_sim_bam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "fcbbd08b-4b6d-4532-bb1b-a140846a700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_mixed_fem_cosine = {}\n",
    "calc_cos_sim(black_mixed_fem_cosine,  mixed_black_fem_avg_sims.keys(), \"black_mixed_fem_cos_sim\", cosine_sim_bmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "1dda8fd7-6af7-45da-a849-de27635aebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_mixed_mal_cosine = {}\n",
    "calc_cos_sim(black_mixed_mal_cosine, mixed_black_mal_avg_sims.keys(), \"black_mixed_mal_cos_sim\", cosine_sim_bmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "766f1aa3-56c0-4d1f-844a-6595aa8e7a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "asian_mixed_fem_cosine = {}\n",
    "calc_cos_sim(asian_mixed_fem_cosine,  asian_mixed_fem_avg_sims.keys(), \"asian_mixed_fem_cos_sim\", cosine_sim_amf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "5db09031-90df-4a31-abfb-b64520870dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "asian_mixed_mal_cosine = {}\n",
    "calc_cos_sim(asian_mixed_mal_cosine,  asian_mixed_mal_avg_sims.keys(), \"asian_mixed_mal_cos_sim\", cosine_sim_amm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "3a0591b6-bffd-4688-8d26-86f47ced10fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_genders_cosine = {}\n",
    "calc_cos_sim(white_genders_cosine,  white_genders_avg_sims.keys(), \"white_genders_cos_sim\", cosine_sim_w_gend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "0680ab15-18f1-4af0-a44f-13720b6a1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_genders_cosine = {}\n",
    "calc_cos_sim(black_genders_cosine,  black_genders_avg_sims.keys(), \"black_genders_cos_sim\", cosine_sim_b_gend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "58d783b2-824a-4830-9cc7-2f280a40de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_genders_cosine = {}\n",
    "calc_cos_sim(mixed_genders_cosine,  mixed_genders_avg_sims.keys(), \"mixed_genders_cos_sim\", cosine_sim_m_gend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "bead92fb-f06d-49f9-9997-a88949b14172",
   "metadata": {},
   "outputs": [],
   "source": [
    "asian_genders_cosine = {}\n",
    "calc_cos_sim(asian_genders_cosine,  asian_genders_avg_sims.keys(), \"asian_genders_cos_sim\", cosine_sim_a_gend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "20061569-5cc4-48cc-b681-869ed64acef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar czf comparisons_embeddings_cosine_sim.tar.gz embedding_similarities/cosine_sim/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a509d504-94fc-4bae-aad9-83e7ac7c5109",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 3: Other Similarity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "4a15e3bf-81ef-4f7d-bec2-72631e427903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leacock_chodorow_calcs(dict1, dict2, sim_dict, dict_name, file_name):\n",
    "    avg_file = open(f\"embedding_similarities/skip_gram_lch/{file_name}.txt\", \"a\")\n",
    "    for word in dict1.keys():\n",
    "        counter = 0\n",
    "        if len(dict1[word]) > 0:\n",
    "            sim_dict[word] = 0\n",
    "            if len(dict1[word]) > 0 and len(dict2[word]) > 0:\n",
    "                for embed1 in dict1[word]:\n",
    "                    for embed2 in dict2[word]:\n",
    "                        text = f\"{embed1} {embed2}\"\n",
    "                        tokens = sp(text)\n",
    "                        sim_score = tokens[0].similarity(tokens[1])\n",
    "                        syn1 = wn.synsets(embed1)\n",
    "                        syn2 = wn.synsets(embed2)\n",
    "                        if len(syn1) > 0 and len(syn2) > 0:\n",
    "                            synonyms = []\n",
    "                            pos1 = \"\"\n",
    "                            for s1 in syn1:\n",
    "                                if s1.name().split(\".\")[0] == embed1:\n",
    "                                    synonyms.append(s1)\n",
    "                                    pos1 = s1.pos()\n",
    "                                    break\n",
    "                            for s2 in syn2:\n",
    "                                if s2.name().split(\".\")[0] == embed2 and s2.pos() == pos1:\n",
    "                                    synonyms.append(s2)\n",
    "                                    break\n",
    "                            if len(synonyms) > 1:\n",
    "                                synon1 = synonyms[0].name().split(\".\")[0]\n",
    "                                synon2 = synonyms[1].name().split(\".\")[0]\n",
    "                                lch = synonyms[0].lch_similarity(synonyms[1])\n",
    "                                m = max(sim_score, lch)\n",
    "                                sim_dict[word] += m\n",
    "                            else:\n",
    "                                sim_dict[word] += sim_score\n",
    "                full_length = len(dict1[word]) * len(dict2[word])\n",
    "                sim_dict[word] /= full_length\n",
    "    sorted_avgs = dict(sorted(sim_dict.items(), key=lambda item: item[1]))\n",
    "    for word in sorted_avgs.keys():\n",
    "        avg_file.write(f\"{dict_name}[{word}] = {sorted_avgs[word]}\\n\")\n",
    "    avg_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "ec01fba1-e9ac-4b00-8a11-4233334c7b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "white_black_fem_lch_sims = {}\n",
    "leacock_chodorow_calcs(white_fem, black_fem, white_black_fem_lch_sims, \"white_black_fem_lch_sims\", \"white_black_f_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "8ec69172-1071-4485-9af6-fe966f40e995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "white_black_mal_lch_sims = {}\n",
    "leacock_chodorow_calcs(white_mal, black_mal, white_black_mal_lch_sims, \"white_black_mal_lch_sims\", \"white_black_m_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "817d3a53-8882-4ea0-bba4-12b916ff3592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "white_asian_fem_lch_sims = {}\n",
    "leacock_chodorow_calcs(white_fem, asian_fem, white_asian_fem_lch_sims, \"white_asian_fem_lch_sims\", \"white_asian_f_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "28af4ca7-fb6d-42df-b8ca-c9d670f0121c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "white_asian_mal_lch_sims = {}\n",
    "leacock_chodorow_calcs(white_mal, asian_mal, white_asian_mal_lch_sims, \"white_asian_mal_lch_sims\", \"white_asian_m_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "75dda845-45c2-425d-93d0-9677df7bc334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "white_mixed_fem_lch_sims = {}\n",
    "leacock_chodorow_calcs(white_fem, mixed_fem, white_mixed_fem_lch_sims, \"white_mixed_fem_lch_sims\", \"white_mixed_f_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "4f284feb-1089-4de0-b341-e503b92893e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "white_mixed_mal_lch_sims = {}\n",
    "leacock_chodorow_calcs(white_mal, mixed_mal, white_mixed_mal_lch_sims, \"white_mixed_mal_lch_sims\", \"white_mixed_m_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "74c2278c-d5f5-48d9-9aa2-e477d7586de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "black_mixed_fem_lch_sims = {}\n",
    "leacock_chodorow_calcs(black_fem, mixed_fem, black_mixed_fem_lch_sims, \"black_mixed_fem_lch_sims\", \"black_mixed_f_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "a0f2ede2-bfb4-4490-9eae-c5d6877bca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_mixed_mal_lch_sims = {}\n",
    "leacock_chodorow_calcs(black_mal, mixed_mal, black_mixed_mal_lch_sims, \"black_mixed_mal_lch_sims\", \"black_mixed_m_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "eae479e5-2729-4a42-8bde-39e5585b39d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "black_asian_fem_lch_sims = {}\n",
    "leacock_chodorow_calcs(black_fem, asian_fem, black_asian_fem_lch_sims, \"black_asian_fem_lch_sims\", \"black_asian_f_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "a5e3380e-dda6-4479-b3b1-fe61a60d3212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "black_asian_mal_lch_sims = {}\n",
    "leacock_chodorow_calcs(black_mal, asian_mal, black_asian_mal_lch_sims, \"black_asian_mal_lch_sims\", \"black_asian_m_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "63f5969f-7c65-4dd0-b04a-ae258ea0d7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "mixed_asian_fem_lch_sims = {}\n",
    "leacock_chodorow_calcs(mixed_fem, asian_fem, mixed_asian_fem_lch_sims, \"mixed_asian_fem_lch_sims\", \"mixed_asian_f_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "4ec8f5db-02ac-43fe-89a1-77af87d0f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_asian_mal_lch_sims = {}\n",
    "leacock_chodorow_calcs(mixed_mal, asian_mal, mixed_asian_mal_lch_sims, \"mixed_asian_mal_lch_sims\", \"mixed_asian_m_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "7374317e-9ab3-4938-a2b9-e575b88070d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "white_genders_lch_sims = {}\n",
    "leacock_chodorow_calcs(white_fem, white_mal, white_genders_lch_sims, \"white_genders_lch_sims\", \"white_genders_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "3888ca18-deaa-4b54-a555-bad582478760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "black_genders_lch_sims = {}\n",
    "leacock_chodorow_calcs(black_fem, black_mal, black_genders_lch_sims, \"black_genders_lch_sims\", \"black_genders_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "21aa57fe-f2b9-4ee3-b705-0228c03396e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "mixed_genders_lch_sims = {}\n",
    "leacock_chodorow_calcs(mixed_fem, mixed_mal, mixed_genders_lch_sims, \"mixed_genders_lch_sims\", \"mixed_genders_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "c62d96ac-f9a9-4e5f-8390-d190a71e7435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1382093/1315639450.py:12: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  sim_score = tokens[0].similarity(tokens[1])\n"
     ]
    }
   ],
   "source": [
    "asian_genders_lch_sims = {}\n",
    "leacock_chodorow_calcs(asian_fem, asian_mal, asian_genders_lch_sims, \"asian_genders_lch_sims\", \"asian_genders_lch_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "06b8d4cf-0d0e-4657-8efb-217105627c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar czf leacock_chodorow_comparisons.tar.gz embedding_similarities/skip_gram_lch/*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368cbfe0-696c-4dba-b474-6137790aed69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e66a1-1b66-41ea-b56d-0faa86911f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
