{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972e3140-e984-453a-83bf-e79f2a7257ce",
   "metadata": {},
   "source": [
    "## Part 1: Simple Wu-Parker Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "868f4bcb-7995-4ef2-9fdd-4368a9bdea3e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.11/site-packages (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.11/site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.11/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Collecting en-core-web-md==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /opt/conda/lib/python3.11/site-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "!pip install -U spacy\n",
    "import spacy\n",
    "!python -m spacy download en_core_web_md \n",
    "sp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b6a56cff-877d-4dec-8644-4e129553877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dict = {}\n",
    "with open(\"embeddings_final/word_embeddings_skip_25.txt\") as embeddings:\n",
    "    emb_dict = json.load(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f1876aa1-7be8-4431-88e9-658f73249053",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "white_fem = {}\n",
    "white_mal = {}\n",
    "black_fem = {}\n",
    "black_mal = {}\n",
    "mixed_fem = {}\n",
    "mixed_mal = {}\n",
    "asian_fem = {}\n",
    "asian_mal = {}\n",
    "for key in emb_dict.keys():\n",
    "    word_info = key.split(\"_\")\n",
    "    word = word_info[0]\n",
    "    ethnic = word_info[1]\n",
    "    gender = word_info[2]\n",
    "    if ethnic == \"white\":\n",
    "        if gender == \"female\":\n",
    "            white_fem[word] = emb_dict[key]\n",
    "        else:\n",
    "            white_mal[word] = emb_dict[key]\n",
    "    elif ethnic == \"black\":\n",
    "        if gender == \"female\":\n",
    "            black_fem[word] = emb_dict[key]\n",
    "        else:\n",
    "            black_mal[word] = emb_dict[key]\n",
    "    elif ethnic == \"mixed\":\n",
    "        if gender == \"female\":\n",
    "            mixed_fem[word] = emb_dict[key]\n",
    "        else:\n",
    "            mixed_mal[word] = emb_dict[key]\n",
    "    elif ethnic == \"asian\":\n",
    "        if gender == \"female\":\n",
    "            asian_fem[word] = emb_dict[key]\n",
    "        else:\n",
    "            asian_mal[word] = emb_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d006813a-bb15-4fa1-bdd1-71b2a3dc3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wu_parker_calcs(dict1, dict2, sim_dict, dict_name, file_name):\n",
    "    avg_file = open(f\"embedding_similarities/skip_gram_wup/{file_name}.txt\", \"a\")\n",
    "    for word in dict1.keys():\n",
    "        counter = 0\n",
    "        if len(dict1[word]) > 0:\n",
    "            dict1[word].sort()\n",
    "            dict2[word].sort()\n",
    "            sim_dict[word] = 0\n",
    "            if len(dict1[word]) > 0 and len(dict2[word]) > 0:\n",
    "                for embed1 in dict1[word]:\n",
    "                    for embed2 in dict2[word]:\n",
    "                        syn1 = wn.synsets(embed1)\n",
    "                        syn2 = wn.synsets(embed2)\n",
    "                        if len(syn1) > 0 and len(syn2) > 0:\n",
    "                            synonyms = []\n",
    "                            c1 = 0\n",
    "                            for s1 in syn1:\n",
    "                                if s1.name().split(\".\")[0] == embed1:\n",
    "                                    synonyms.append(s1)\n",
    "                                    break\n",
    "                            for s2 in syn2:\n",
    "                                if s2.name().split(\".\")[0] == embed2:\n",
    "                                    synonyms.append(s2)\n",
    "                                    break\n",
    "                            if len(synonyms) > 1:\n",
    "                                sim_dict[word] += synonyms[0].wup_similarity(synonyms[0])\n",
    "                            else:\n",
    "                                sim_dict[word] += syn1[0].wup_similarity(syn2[0])\n",
    "                full_length = len(dict1[word]) * len(dict2[word])\n",
    "                sim_dict[word] /= full_length\n",
    "    sorted_avgs = dict(sorted(sim_dict.items(), key=lambda item: item[1]))\n",
    "    for word in sorted_avgs.keys():\n",
    "        avg_file.write(f\"{dict_name}[{word}] = {sorted_avgs[word]}\\n\")\n",
    "    avg_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d6eed8ac-fdee-4ccf-ab66-3419c514ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_black_fem_avg_sims = {}\n",
    "wu_parker_calcs(white_fem, black_fem, white_black_fem_avg_sims, \"white_black_fem_avg_sims\", \"white_black_f_avg_sim_skipgram\")\n",
    "\n",
    "white_black_mal_avg_sims = {}\n",
    "wu_parker_calcs(white_mal, black_mal, white_black_mal_avg_sims, \"white_black_mal_avg_sims\", \"white_black_m_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "55cb9a50-8b7d-4f78-8c63-0eb51fff1536",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_asian_fem_avg_sims = {}\n",
    "wu_parker_calcs(white_fem, asian_fem, white_asian_fem_avg_sims, \"white_asian_fem_avg_sims\", \"white_asian_f_avg_sim_skipgram\")\n",
    "\n",
    "white_asian_mal_avg_sims = {}\n",
    "wu_parker_calcs(white_mal, asian_mal, white_asian_mal_avg_sims, \"white_asian_mal_avg_sims\", \"white_asian_m_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c4b7d57a-3429-4846-86da-e3ab5f8e174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_mixed_fem_avg_sims = {}\n",
    "wu_parker_calcs(white_fem, mixed_fem, white_mixed_fem_avg_sims, \"white_mixed_fem_avg_sims\", \"white_male_f_avg_sim_skipgram\")\n",
    "\n",
    "white_mixed_mal_avg_sims = {}\n",
    "wu_parker_calcs(white_mal, mixed_mal, white_mixed_mal_avg_sims, \"white_mixed_mal_avg_sims\", \"white_male_m_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "575451be-01b8-4093-99fa-76e724b7004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_black_fem_avg_sims = {}\n",
    "wu_parker_calcs(mixed_fem, black_fem, mixed_black_fem_avg_sims, \"mixed_black_fem_avg_sims\", \"mixed_black_f_avg_sim_skipgram\")\n",
    "\n",
    "mixed_black_mal_avg_sims = {}\n",
    "wu_parker_calcs(mixed_mal, black_mal, mixed_black_mal_avg_sims, \"mixed_black_mal_avg_sims\", \"mixed_black_m_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "13a5dca0-e59f-4906-9403-cd8ac7be74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "asian_black_fem_avg_sims = {}\n",
    "wu_parker_calcs(asian_fem, black_fem, asian_black_fem_avg_sims, \"asian_black_fem_avg_sims\", \"asian_black_f_avg_sim_skipgram\")\n",
    "\n",
    "asian_black_mal_avg_sims = {}\n",
    "wu_parker_calcs(asian_mal, black_mal, asian_black_mal_avg_sims, \"asian_black_mal_avg_sims\", \"asian_black_m_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e23d3e01-7bab-4f48-be25-a46431b8bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_genders_avg_sims = {}\n",
    "wu_parker_calcs(black_fem, black_mal, black_genders_avg_sims, \"black_genders_avg_sims\", \"black_genders_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "25a66d2b-d149-43a0-ad58-0ad6f404c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_genders_avg_sims = {}\n",
    "wu_parker_calcs(white_fem, white_mal, white_genders_avg_sims, \"white_genders_avg_sims\", \"white_genders_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "04fbcb61-a06b-49af-8e82-492830617825",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_genders_avg_sims = {}\n",
    "wu_parker_calcs(mixed_fem, mixed_mal, mixed_genders_avg_sims, \"mixed_genders_avg_sims\", \"mixed_genders_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3e3a71bc-d7cf-405b-8b54-85a020d2b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "asian_genders_avg_sims = {}\n",
    "wu_parker_calcs(asian_fem, asian_mal, asian_genders_avg_sims, \"asian_genders_avg_sims\", \"asian_genders_avg_sim_skipgram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c8fe0170-09a4-4b0d-9c0c-556a0bfcc941",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar czf comparisons_embeddings.tar.gz embedding_similarities/skip_gram_wup/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a81fb-25b3-400e-8b6f-c82d9e883af8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 2: Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12fabae-6795-4e61-8dbd-d34889b1fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba566615-e018-4d90-b2d8-c13a37f1b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vocab(model, top_n = None):\n",
    "    count = 0\n",
    "    if top_n is not None:\n",
    "        for index, word in enumerate(model.wv.index_to_key):\n",
    "            count+= 1\n",
    "            if count < top_n:\n",
    "                print(f\"WORD #{index}/{len(model.wv.index_to_key)} IS: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983bb050-ac2a-43df-afa6-d8b80ec98163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_align_gensim(m1, m2, words=None):\n",
    "    vocab_m1 = set(m1.wv.index_to_key)\n",
    "    vocab_m2 = set(m2.wv.index_to_key)\n",
    "    common_vocab = vocab_m1 & vocab_m2\n",
    "    if words: common_vocab &= set(words)\n",
    "    if not vocab_m1 - common_vocab and not vocab_m2 - common_vocab:\n",
    "        return (m1,m2)\n",
    "\n",
    "    common_vocab = list(common_vocab)\n",
    "    common_vocab.sort(key=lambda w: m1.wv.get_vecattr(w, \"count\") + m2.wv.get_vecattr(w, \"count\"), reverse=True)\n",
    "    for m in [m1, m2]:\n",
    "        indices = [m.wv.key_to_index[w] for w in common_vocab]\n",
    "        old_arr = m.wv.vectors\n",
    "        new_arr = np.array([old_arr[index] for index in indices])\n",
    "        m.wv.vectors = new_arr\n",
    "\n",
    "        new_key_to_index = {}\n",
    "        new_index_to_key = []\n",
    "        for new_index, key in enumerate(common_vocab):\n",
    "            new_key_to_index[key] = new_index\n",
    "            new_index_to_key.append(key)\n",
    "        m.wv.key_to_index = new_key_to_index\n",
    "        m.wv.index_to_key = new_index_to_key\n",
    "        \n",
    "        print(len(m.wv.key_to_index), len(m.wv.vectors))\n",
    "        \n",
    "    return (m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa4b4f-90d4-493f-86f3-b07d104af490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_procrustes_align_gensim(base_embed, other_embed, words=None):\n",
    "    in_base_embed, in_other_embed = intersection_align_gensim(base_embed, other_embed, words=words)\n",
    "\n",
    "    base_vecs = in_base_embed.wv.get_normed_vectors()\n",
    "    other_vecs = in_other_embed.wv.get_normed_vectors()\n",
    "\n",
    "    m = other_vecs.T.dot(base_vecs) \n",
    "    u, _, v = np.linalg.svd(m)\n",
    "    ortho = u.dot(v) \n",
    "    other_embed.wv.vectors = (other_embed.wv.vectors).dot(ortho)    \n",
    "    \n",
    "    return other_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c71ff9-c9a8-4fdd-95a6-6f33060677d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_fem_mod = Word2Vec.load(\"white_models/cbow_w10_f1_1000_ns_half_neg2\")\n",
    "white_mal_mod = Word2Vec.load(\"white_models/cbow_w3_f1_1000\")\n",
    "\n",
    "black_fem_mod = Word2Vec.load(\"black_models/cbow_w10_f1_1000_ns_half_neg3\")\n",
    "black_mal_mod = Word2Vec.load(\"black_models/cbow_w10_f1_1000_mc2\")\n",
    "\n",
    "mixed_fem_mod = Word2Vec.load(\"mixed_models/cbow_w10_f1_1000_mc2\")\n",
    "mixed_mal_mod = Word2Vec.load(\"mixed_models/cbow_w10_f1_1000_mc2\")\n",
    "\n",
    "asian_fem_mod = Word2Vec.load(\"asian_models/cbow_w10_f1_1000\")\n",
    "asian_mal_mod = Word2Vec.load(\"asian_models/cbow_w10_f1_1000_mc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dcbc88-f197-4f1b-90c2-f1bcedb271e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(model1, model2, word):\n",
    "  sc = 1 - spatial.distance.cosine(model1.wv[word], model2.wv[word])\n",
    "  return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303bcae-80fd-46aa-bb53-62cb1c87790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_procrustes_align_gensim(white_fem_mod, black_fem_mod, words=None)\n",
    "cosine_sim_wbf = pd.DataFrame(([w, cosine_similarity(white_fem_mod, black_fem_mod, w), white_fem_mod.wv.get_vecattr(w, \"count\") , black_fem_mod.wv.get_vecattr(w, \"count\") ] for w in white_fem_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for white-black female comparison\")\n",
    "\n",
    "white_fem_mod = Word2Vec.load(\"white_models/cbow_w10_f1_1000_ns_half_neg2\")\n",
    "black_fem_mod = Word2Vec.load(\"black_models/cbow_w10_f1_1000_ns_half_neg3\")\n",
    "\n",
    "smart_procrustes_align_gensim(white_fem_mod, asian_fem_mod, words=None)\n",
    "cosine_sim_waf = pd.DataFrame(([w, cosine_similarity(white_fem_mod, asian_fem_mod, w), white_fem_mod.wv.get_vecattr(w, \"count\") , asian_fem_mod.wv.get_vecattr(w, \"count\") ] for w in white_fem_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for white-asian female comparison\")\n",
    "\n",
    "white_fem_mod = Word2Vec.load(\"white_models/cbow_w10_f1_1000_ns_half_neg2\")\n",
    "asian_fem_mod = Word2Vec.load(\"asian_models/cbow_w10_f1_1000\")\n",
    "\n",
    "smart_procrustes_align_gensim(black_fem_mod, asian_fem_mod, words=None)\n",
    "cosine_sim_waf = pd.DataFrame(([w, cosine_similarity(black_fem_mod, asian_fem_mod, w), black_fem_mod.wv.get_vecattr(w, \"count\") , asian_fem_mod.wv.get_vecattr(w, \"count\") ] for w in black_fem_mod.wv.index_to_key), columns = ('word', 'similarity', \"frequency_t1\", \"frequency_t2\"))\n",
    "print(\"Created dataframe for black-asian female comparison\")\n",
    "asian_fem_mod = Word2Vec.load(\"asian_models/cbow_w10_f1_1000\")\n",
    "black_fem_mod = Word2Vec.load(\"black_models/cbow_w10_f1_1000_ns_half_neg3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f0b0e-5d49-4e03-aaab-cdd43100faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"White female model top vocab: \")\n",
    "print_vocab(white_fem_mod, 15)\n",
    "print(\"Black female model top vocab: \")\n",
    "print_vocab(black_fem_mod, 15)\n",
    "# print(\"Mixed female model top vocab: \")\n",
    "# print_vocab(mixed_fem_mod, 15)\n",
    "# print(\"Asian female model top vocab: \")\n",
    "# print_vocab(asian_fem_mod, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0727888-e886-4850-abbd-8b25ca2aae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_black_fem_cosine = {}\n",
    "default_words_cosine = {}\n",
    "\n",
    "word_list = white_black_avg_sims.keys()\n",
    "defaults = [\"please\", \"service\", \"time\", \"contact\", \"Team\", \"Dr\", \"mental\"]\n",
    "\n",
    "wb_fem_default = cosine_sim_wbf[cosine_sim_wbf['word'].isin(defaults)]\n",
    "wb_fem_default.sort_values(by=['similarity'], inplace=True)\n",
    "for index in range(wb_fem_default.shape[0]):\n",
    "    default_words_cosine[wb_fem_default['word'].iloc[index]] = wb_fem_default['similarity'].iloc[index]\n",
    "with open('embedding_similarities/wbf_defaults_cos_sim.txt', 'w') as default_file:\n",
    "    json.dump(default_words_cosine, default_file, indent=2)\n",
    "\n",
    "wb_fem_comparisons = cosine_sim_wbf[cosine_sim_wbf['word'].isin(word_list)]\n",
    "wb_fem_comparisons.sort_values(by=['similarity'], inplace=True)\n",
    "for index in range(wb_fem_comparisons.shape[0]):\n",
    "    white_black_fem_cosine[wb_fem_comparisons['word'].iloc[index]] = wb_fem_comparisons['similarity'].iloc[index]\n",
    "# with open('embedding_similarities/wbf_cos_sim.txt', 'w') as wbf_file:\n",
    "#     json.dump(white_black_fem_cosine, wbf_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4fda3-5efc-49bd-95e8-e01ff4163979",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_asian_fem_cosine = {}\n",
    "word_list = white_asian_avg_sims.keys()\n",
    "wa_fem_comparisons = cosine_sim_waf[cosine_sim_waf['word'].isin(word_list)]\n",
    "wa_fem_comparisons.sort_values(by=['similarity'], inplace=True)\n",
    "display(wa_fem_comparisons)\n",
    "\n",
    "for index in range(wa_fem_comparisons.shape[0]):\n",
    "    white_asian_fem_cosine[wa_fem_comparisons['word'].iloc[index]] = wa_fem_comparisons['similarity'].iloc[index]\n",
    "with open('embedding_similarities/waf_cos_sim.txt', 'w') as waf_file:\n",
    "    json.dump(white_asian_fem_cosine, waf_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a2d0b-ce28-4242-823c-a635952620d7",
   "metadata": {},
   "source": [
    "## Part 3: NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01fd2a-d777-4d2c-a21e-7eb35fdef727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import ndcg_score\n",
    "score_wbf_black = ndcg_score(np.asarray([white_black_avg_sims.values()]), np.asarray([black_genders_avg_sims.values()]))\n",
    "score_wbf_white = ndcg_score(np.asarray([white_black_avg_sims.values()]), np.asarray([white_genders_avg_sims.values()]))\n",
    "\n",
    "print(f\"BLACK M/F VS WHITE/BLACK F: {score_wbf_black}\")\n",
    "print(f\"WHITE M/F VS WHITE/BLACK F: {score_wbf_white}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd035aa3-c1cb-4e93-a73d-c50ff6d863d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
